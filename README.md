# üöÄ plateforme-de-scoring-fraude-chargement-vers-Snowflake: Pipelines fiables pour l‚Äôingestion et la transformation des donn√©es

## üéØ Objectif
Mettre en place des pipelines **batch**, **streaming**, et de **qualit√© de donn√©es** afin d‚Äôassurer la fiabilit√©, la coh√©rence et la fra√Æcheur des donn√©es pour les analyses.

---

## üß© Structure du Projet

```bash
fraud_scoring_platform/
‚îú‚îÄ‚îÄ dags/
‚îÇ   ‚îú‚îÄ‚îÄ dag_batch_customers_transactions.py      # DAG Airflow pour le pipeline batch (extraction CRM + transactions J-1)
‚îÇ   ‚îú‚îÄ‚îÄ dag_streaming_transactions.py            # DAG Airflow pour le pipeline streaming (transactions en temps r√©el)
‚îÇ   ‚îî‚îÄ‚îÄ dag_data_quality.py                      # DAG Airflow pour la validation et le reporting de la qualit√©
‚îÇ
‚îú‚îÄ‚îÄ jobs/
‚îÇ   ‚îú‚îÄ‚îÄ batch/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ extraction.py                        # Extraction des donn√©es CRM et transactions
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ transform_pyspark.py                 # Nettoyage et transformation PySpark
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ load_warehouse.py                    # Chargement dans Snowflake / BigQuery
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ streaming/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ streaming_job.py                     # Job Spark Structured Streaming avec Kafka
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ feature_engineering.py               # Calcul des moyennes glissantes et d√©tection d‚Äôanomalies
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sink_snowflake.py                    # √âcriture vers Snowflake / BigQuery
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ quality/
‚îÇ       ‚îú‚îÄ‚îÄ great_expectations_checks.py         # D√©finition des r√®gles Great Expectations
‚îÇ       ‚îú‚îÄ‚îÄ generate_quality_report.py           # G√©n√©ration du rapport de qualit√© hebdomadaire
‚îÇ       ‚îî‚îÄ‚îÄ notify_quality_status.py             # Notification (Slack/Email)
‚îÇ
‚îú‚îÄ‚îÄ configs/
‚îÇ   ‚îú‚îÄ‚îÄ airflow_config.yaml                      # Configuration Airflow (connexions, scheduling)
‚îÇ   ‚îú‚îÄ‚îÄ spark_config.yaml                        # Configuration Spark (batch et streaming)
‚îÇ   ‚îú‚îÄ‚îÄ warehouse_config.yaml                    # Connexions Snowflake/BigQuery
‚îÇ   ‚îî‚îÄ‚îÄ quality_rules.yaml                       # R√®gles de validation de la qualit√© des donn√©es
‚îÇ
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ logger.py                                # Gestion des logs centralis√©s
‚îÇ   ‚îú‚îÄ‚îÄ monitoring.py                            # Suivi de la latence et m√©triques
‚îÇ   ‚îú‚îÄ‚îÄ schema_validation.py                     # Validation de sch√©ma Avro/Parquet
‚îÇ   ‚îî‚îÄ‚îÄ helpers.py                               # Fonctions utilitaires g√©n√©riques
‚îÇ
‚îú‚îÄ‚îÄ reports/
‚îÇ   ‚îú‚îÄ‚îÄ data_quality_report.html                 # Rapport g√©n√©r√© automatiquement par Great Expectations
‚îÇ   ‚îî‚îÄ‚îÄ metrics_dashboard.csv                    # Indicateurs de qualit√© et volum√©trie
‚îÇ
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ test_batch_pipeline.py                   # Tests unitaires du pipeline batch
‚îÇ   ‚îú‚îÄ‚îÄ test_streaming_pipeline.py               # Tests du pipeline temps r√©el
‚îÇ   ‚îî‚îÄ‚îÄ test_data_quality.py                     # Tests des r√®gles de validation
‚îÇ
‚îú‚îÄ‚îÄ Dockerfile                                   # Image Airflow + Spark + GE
‚îú‚îÄ‚îÄ requirements.txt                             # D√©pendances Python
‚îî‚îÄ‚îÄ README.md
```
---
## üîÑ Pipeline global

```mermaid
flowchart TD
    %% =====================================
    %% üèóÔ∏è Pipeline Data Engineering vertical
    %% =====================================

    %% Niveau 1 : ETL
    subgraph ETL["üèóÔ∏è ETL & Data Pipeline"]
        A["üì• Extraction CRM et Transactions J-1"]
        B["üßπ Transformation PySpark"]
        C["üè¶ Chargement dans Snowflake ou BigQuery"]
    end

    %% Niveau 2 : Streaming & Features
    subgraph STREAM["‚ö° Pipeline Streaming & Feature Engineering"]
        D["üìä Pipeline Kafka Streaming"]
        E["üß† Feature Engineering (moyennes glissantes, anomalies)"]
        F["üèÅ Sink vers Snowflake ou BigQuery"]
    end

    %% Niveau 3 : Qualit√© & Monitoring
    subgraph QUALITY["‚úÖ Contr√¥le Qualit√© & Monitoring"]
        G["üßæ Great Expectations : validation des donn√©es"]
        H["üìà Rapport qualit√© hebdomadaire"]
        I["üìß Notification Slack/Email"]
    end

    %% Niveau 4 : Ops / CI-CD
    subgraph OPS["‚ò∏Ô∏è Orchestration & CI/CD"]
        J["ü™∂ Airflow DAGs : orchestration ETL/Streaming"]
        K["‚öôÔ∏è GitHub Actions : tests et d√©ploiement automatique"]
        L["üìä Monitoring : logs, alertes, dashboards"]
    end

    %% üîó Flux hi√©rarchique vertical
    ETL --> STREAM --> QUALITY --> OPS
    A --> B --> C --> D --> E --> F --> G --> H --> I
    J --> ETL
    J --> STREAM
    K --> ETL
    K --> STREAM
    L --> QUALITY


```
---
## ‚öôÔ∏è Stack Technique
- **Orchestration** : Apache Airflow
- **Traitement batch** : PySpark
- **Traitement temps r√©el** : Spark Structured Streaming + Kafka
- **Stockage analytique** : Snowflake / BigQuery
- **Qualit√© des donn√©es** : Great Expectations
- **Monitoring** : Airflow + Logs + Metrics

## üöÄ Ex√©cution

```bash
# Lancer Airflow
docker-compose up airflow-webserver airflow-scheduler

# D√©clencher le DAG batch manuellement
airflow dags trigger dag_batch_customers_transactions

# Visualiser le rapport de qualit√©
open reports/data_quality_report.html

```

