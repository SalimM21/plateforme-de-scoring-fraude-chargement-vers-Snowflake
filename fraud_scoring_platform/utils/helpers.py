# Fonctions utilitaires g√©n√©riques
"""
--------------------------------------------------------------------
Module utilitaire regroupant les fonctions g√©n√©riques utilis√©es dans
les pipelines batch, streaming et qualit√© :
- Gestion des dates (timestamps, intervalles)
- Lecture de fichiers de configuration YAML
- Manipulation de chemins et nettoyage de donn√©es
- Helpers pour connexions Cloud (GCP / Snowflake)
--------------------------------------------------------------------
"""

import os
import yaml
import json
import datetime
import pytz
from typing import Any, Dict, Optional
from logger import CentralizedLogger


logger = CentralizedLogger("helpers")


# ==========================================================
# üïì Fonctions de gestion de temps
# ==========================================================

def get_current_timestamp(tz: str = "UTC") -> str:
    """Retourne un timestamp ISO format√© selon un fuseau horaire."""
    timezone = pytz.timezone(tz)
    return datetime.datetime.now(timezone).strftime("%Y-%m-%dT%H:%M:%S")


def get_yesterday_date() -> str:
    """Retourne la date d‚Äôhier au format YYYY-MM-DD."""
    yesterday = datetime.date.today() - datetime.timedelta(days=1)
    return yesterday.strftime("%Y-%m-%d")


def get_date_n_days_ago(n: int) -> str:
    """Retourne la date N jours en arri√®re au format YYYY-MM-DD."""
    date = datetime.date.today() - datetime.timedelta(days=n)
    return date.strftime("%Y-%m-%d")


# ==========================================================
# ‚öôÔ∏è Fonctions de configuration
# ==========================================================

def load_yaml_config(path: str) -> Dict[str, Any]:
    """Charge un fichier YAML de configuration."""
    try:
        with open(path, "r", encoding="utf-8") as f:
            config = yaml.safe_load(f)
        logger.info(f"Configuration charg√©e : {path}")
        return config
    except Exception as e:
        logger.error(f"Erreur lors du chargement du fichier YAML {path}: {e}")
        return {}


def load_json_config(path: str) -> Dict[str, Any]:
    """Charge un fichier JSON de configuration."""
    try:
        with open(path, "r", encoding="utf-8") as f:
            config = json.load(f)
        logger.info(f"Configuration JSON charg√©e : {path}")
        return config
    except Exception as e:
        logger.error(f"Erreur lors du chargement du fichier JSON {path}: {e}")
        return {}


# ==========================================================
# üß© Helpers pour chemins et fichiers
# ==========================================================

def ensure_dir_exists(directory: str):
    """Cr√©e un r√©pertoire s‚Äôil n‚Äôexiste pas."""
    if not os.path.exists(directory):
        os.makedirs(directory, exist_ok=True)
        logger.info(f"R√©pertoire cr√©√© : {directory}")
    else:
        logger.debug(f"R√©pertoire d√©j√† existant : {directory}")


def list_files_with_extension(directory: str, extension: str) -> list:
    """Liste tous les fichiers avec une extension donn√©e dans un dossier."""
    files = [
        os.path.join(directory, f)
        for f in os.listdir(directory)
        if f.endswith(extension)
    ]
    logger.info(f"{len(files)} fichiers trouv√©s avec extension '{extension}' dans {directory}")
    return files


def clean_column_names(df):
    """Nettoie les noms de colonnes dans un DataFrame Spark ou Pandas."""
    new_cols = [col.lower().replace(" ", "_").replace("-", "_") for col in df.columns]
    logger.info("Nettoyage des noms de colonnes effectu√©.")
    df = df.toDF(*new_cols) if hasattr(df, "toDF") else df.rename(columns=dict(zip(df.columns, new_cols)))
    return df


# ==========================================================
# ‚òÅÔ∏è Helpers Cloud
# ==========================================================

def build_gcs_path(bucket_name: str, file_name: str, prefix: Optional[str] = None) -> str:
    """Construit un chemin complet vers un objet GCS."""
    path = f"gs://{bucket_name}/{prefix}/{file_name}" if prefix else f"gs://{bucket_name}/{file_name}"
    logger.debug(f"Chemin GCS g√©n√©r√© : {path}")
    return path


def build_snowflake_stage_path(database: str, schema: str, stage: str, file_name: str) -> str:
    """Construit le chemin d‚Äôun fichier dans un stage Snowflake."""
    path = f"@{database}.{schema}.{stage}/{file_name}"
    logger.debug(f"Chemin Snowflake stage g√©n√©r√© : {path}")
    return path


# ==========================================================
# üß† Divers
# ==========================================================

def safe_cast(value: Any, to_type: type, default: Any = None) -> Any:
    """Convertit une valeur en un type donn√© sans lever d‚Äôexception."""
    try:
        return to_type(value)
    except (ValueError, TypeError):
        logger.warning(f"Impossible de caster {value} en {to_type.__name__}, valeur par d√©faut utilis√©e.")
        return default


def print_json_pretty(data: Dict[str, Any]):
    """Affiche un JSON de mani√®re lisible."""
    print(json.dumps(data, indent=4, ensure_ascii=False))


# Exemple d'utilisation autonome
if __name__ == "__main__":
    print("Timestamp actuel :", get_current_timestamp("Africa/Casablanca"))
    print("Date J-1 :", get_yesterday_date())

    config = load_yaml_config("configs/airflow_config.yaml")
    print_json_pretty(config)
